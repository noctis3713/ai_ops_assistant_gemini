#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Token è¨ˆç®—å’Œæˆæœ¬ä¼°ç®—æ¨¡çµ„

å°ˆè²¬è™•ç† AI æœå‹™çš„ Token è¨ˆç®—ã€æˆæœ¬ä¼°ç®—å’Œä½¿ç”¨è¨˜éŒ„ï¼š
- çµ±ä¸€çš„ Token ä½¿ç”¨é‡æå–ä»‹é¢
- ç²¾ç¢ºå’Œä¼°ç®—å…©ç¨®è¨ˆç®—æ¨¡å¼
- æˆæœ¬è¨ˆç®—å’Œæ—¥èªŒè¨˜éŒ„
- æ”¯æ´ Claude å’Œ Gemini é›™å¼•æ“

Created: 2025-09-03
Author: Claude Code Assistant
"""

import logging
import time
from typing import Any, Dict, Optional

logger = logging.getLogger(__name__)


class TokenCalculator:
    """Token è¨ˆç®—å’Œæˆæœ¬ä¼°ç®—æ ¸å¿ƒé¡åˆ¥

    æä¾›çµ±ä¸€çš„ Token è¨ˆç®—ä»‹é¢ï¼Œæ”¯æ´ç²¾ç¢ºæå–å’Œæ–‡æœ¬ä¼°ç®—å…©ç¨®æ¨¡å¼ã€‚
    """

    # Claude å®šåƒ¹ï¼ˆæ¯ 1,000 tokensï¼‰
    CLAUDE_PRICING = {
        "claude-3-haiku-20240307": {"input": 0.00025, "output": 0.00125},
        "claude-3-5-haiku-20241022": {"input": 0.00025, "output": 0.00125},
        "claude-3-sonnet-20240229": {"input": 0.003, "output": 0.015},
        "claude-3-5-sonnet-20241022": {"input": 0.003, "output": 0.015},
        "claude-3-opus-20240229": {"input": 0.015, "output": 0.075},
    }

    # Gemini å®šåƒ¹ï¼ˆæ¯ 1,000 tokensï¼‰
    GEMINI_PRICING = {
        "gemini-1.5-flash": {"input": 0.00015, "output": 0.0006},
        "gemini-1.5-flash-latest": {"input": 0.00015, "output": 0.0006},
        "gemini-1.5-pro": {"input": 0.00125, "output": 0.005},
        "gemini-1.5-pro-latest": {"input": 0.00125, "output": 0.005},
        "gemini-pro": {"input": 0.000125, "output": 0.000375},
    }

    def extract_token_usage(self, result: Any) -> Dict[str, Any]:
        """çµ±ä¸€çš„ Token ä½¿ç”¨é‡æå–ä»‹é¢

        æ™ºèƒ½æå– AI æŸ¥è©¢çµæœä¸­çš„ Token ä½¿ç”¨é‡è³‡è¨Šï¼Œ
        æ”¯æ´å¤šç¨®è³‡æ–™ä¾†æºå’Œæ ¼å¼ã€‚

        Args:
            result: AI æŸ¥è©¢çµæœç‰©ä»¶

        Returns:
            Dict: åŒ…å« input_tokens, output_tokens, total_tokens çš„å­—å…¸
        """
        usage_data = {}

        # æ–¹æ³•1: å¾ callback handler å–å¾—ï¼ˆå„ªå…ˆï¼‰
        if hasattr(result, "usage_callback") and result.usage_callback:
            callback_data = getattr(result.usage_callback, "usage_metadata", {})
            if callback_data:
                usage_data.update(self._parse_callback_data(callback_data))
                logger.debug(f"å¾ callback å–å¾— token æ•¸æ“š: {usage_data}")

        # æ–¹æ³•2: å¾çµæœ metadata ä¸­æå–
        if not usage_data and isinstance(result, dict):
            if "usage_metadata" in result:
                usage_data.update(result["usage_metadata"])
                logger.debug(f"å¾çµæœ metadata å–å¾— token æ•¸æ“š: {usage_data}")

            # æª¢æŸ¥ Gemini ç‰¹æ®Šæ ¼å¼
            gemini_tokens = self._extract_gemini_usage(result)
            if gemini_tokens:
                usage_data.update(gemini_tokens)

        # ç¢ºä¿åŒ…å« total_tokens
        if usage_data and "total_tokens" not in usage_data:
            input_tokens = usage_data.get("input_tokens", 0)
            output_tokens = usage_data.get("output_tokens", 0)
            if input_tokens > 0 or output_tokens > 0:
                usage_data["total_tokens"] = input_tokens + output_tokens

        return usage_data

    def estimate_token_usage(self, input_text: str, output_text: str) -> Dict[str, Any]:
        """åŸºæ–¼æ–‡æœ¬ä¼°ç®— Token ä½¿ç”¨é‡

        ç•¶ç„¡æ³•å¾ API å›æ‡‰ä¸­å–å¾—ç²¾ç¢º Token æ•¸æ“šæ™‚ä½¿ç”¨ã€‚

        Args:
            input_text: è¼¸å…¥æ–‡æœ¬
            output_text: è¼¸å‡ºæ–‡æœ¬

        Returns:
            Dict: åŒ…å«ä¼°ç®—çš„ token ä½¿ç”¨é‡ï¼Œæ¨™è¨˜ç‚ºä¼°ç®—å€¼
        """
        try:
            input_tokens = self._estimate_tokens(input_text)
            output_tokens = self._estimate_tokens(output_text)
            total_tokens = input_tokens + output_tokens

            return {
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "total_tokens": total_tokens,
                "estimated": True,
                "method": "char_based_estimation",
            }
        except Exception as e:
            logger.debug(f"Token ä¼°ç®—å¤±æ•—: {e}")
            return {}

    def calculate_cost(
        self, provider: str, model: str, input_tokens: int, output_tokens: int
    ) -> float:
        """è¨ˆç®— Token ä½¿ç”¨æˆæœ¬

        Args:
            provider: AI æä¾›è€… (claude/gemini)
            model: æ¨¡å‹åç¨±
            input_tokens: è¼¸å…¥ token æ•¸é‡
            output_tokens: è¼¸å‡º token æ•¸é‡

        Returns:
            float: ä¼°ç®—æˆæœ¬ï¼ˆç¾å…ƒï¼‰
        """
        try:
            if provider == "claude":
                pricing = self.CLAUDE_PRICING.get(model)
                if not pricing:
                    # ä½¿ç”¨ Sonnet ä½œç‚ºé è¨­å®šåƒ¹
                    pricing = self.CLAUDE_PRICING["claude-3-5-sonnet-20241022"]
            elif provider == "gemini":
                pricing = self.GEMINI_PRICING.get(model)
                if not pricing:
                    # ä½¿ç”¨ Pro ä½œç‚ºé è¨­å®šåƒ¹
                    pricing = self.GEMINI_PRICING["gemini-1.5-pro"]
            else:
                return 0.0

            # è¨ˆç®—æˆæœ¬ï¼š(tokens / 1000) * price_per_1000
            input_cost = (input_tokens / 1000.0) * pricing["input"]
            output_cost = (output_tokens / 1000.0) * pricing["output"]
            total_cost = input_cost + output_cost

            return round(total_cost, 6)  # ä¿ç•™ 6 ä½å°æ•¸

        except Exception as e:
            logger.warning(f"æˆæœ¬è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

    def _parse_callback_data(self, callback_data: Dict) -> Dict[str, int]:
        """è§£æ callback æ•¸æ“šçµæ§‹"""
        if isinstance(callback_data, dict):
            # è™•ç†åµŒå¥—çš„ callback æ•¸æ“šçµæ§‹
            for key, value in callback_data.items():
                if isinstance(value, dict) and "input_tokens" in value:
                    return value
            # å¦‚æœæ²’æœ‰åµŒå¥—çµæ§‹ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•¸æ“š
            if "input_tokens" in callback_data:
                return callback_data
        return {}

    def _extract_gemini_usage(self, result: Dict) -> Dict[str, int]:
        """æå– Gemini ç‰¹å®šçš„ token ä½¿ç”¨é‡æ ¼å¼"""
        try:
            # æª¢æŸ¥ response_metadata
            if "response_metadata" in result:
                metadata = result["response_metadata"]
                return self._parse_gemini_metadata(metadata)

            # æª¢æŸ¥å…¶ä»–å¯èƒ½çš„ä½ç½®
            if "output" in result and hasattr(result["output"], "response_metadata"):
                return self._parse_gemini_metadata(result["output"].response_metadata)

        except Exception as e:
            logger.debug(f"æå– Gemini token ä½¿ç”¨é‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return {}

    def _parse_gemini_metadata(self, metadata: Dict) -> Dict[str, int]:
        """è§£æ Gemini çš„ metadata æ ¼å¼"""
        try:
            usage_keys = ["usage_metadata", "token_count", "usage"]

            for key in usage_keys:
                if key in metadata:
                    usage_info = metadata[key]
                    if isinstance(usage_info, dict):
                        # æ¨™æº–æ ¼å¼
                        if (
                            "input_tokens" in usage_info
                            and "output_tokens" in usage_info
                        ):
                            return usage_info

                        # Gemini ç‰¹å®šæ ¼å¼
                        input_tokens = usage_info.get(
                            "promptTokenCount", usage_info.get("prompt_token_count", 0)
                        )
                        output_tokens = usage_info.get(
                            "candidatesTokenCount",
                            usage_info.get("candidates_token_count", 0),
                        )
                        total_tokens = usage_info.get(
                            "totalTokenCount", usage_info.get("total_token_count", 0)
                        )

                        if input_tokens > 0 or output_tokens > 0:
                            return {
                                "input_tokens": input_tokens,
                                "output_tokens": output_tokens,
                                "total_tokens": total_tokens
                                or (input_tokens + output_tokens),
                            }

        except Exception as e:
            logger.debug(f"è§£æ Gemini metadata æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        return {}

    def _estimate_tokens(self, text: str) -> int:
        """ä¼°ç®—æ–‡æœ¬çš„ token æ•¸é‡

        åŸºæ–¼ç¶“é©—å…¬å¼ï¼š
        - è‹±æ–‡ï¼šç´„ 4 å­—ç¬¦ = 1 token
        - ä¸­æ–‡ï¼šç´„ 2 å­—ç¬¦ = 1 token

        Args:
            text: è¦ä¼°ç®—çš„æ–‡æœ¬

        Returns:
            int: ä¼°ç®—çš„ token æ•¸é‡
        """
        if not text:
            return 0

        char_count = len(text)

        # çµ±è¨ˆä¸­æ–‡å­—ç¬¦æ•¸é‡
        chinese_chars = sum(1 for char in text if "\u4e00" <= char <= "\u9fff")
        english_chars = char_count - chinese_chars

        # ä¸­æ–‡ï¼š2 å­—ç¬¦ = 1 tokenï¼Œè‹±æ–‡ï¼š4 å­—ç¬¦ = 1 token
        estimated_tokens = (chinese_chars / 2.0) + (english_chars / 4.0)

        return max(1, int(estimated_tokens)) if text.strip() else 0


class TokenLogger:
    """Token ä½¿ç”¨è¨˜éŒ„å’Œé¡¯ç¤ºé¡åˆ¥

    å°ˆè²¬è™•ç† Token ä½¿ç”¨é‡çš„æ—¥èªŒè¨˜éŒ„å’Œæ§åˆ¶å°é¡¯ç¤ºã€‚
    """

    def __init__(self):
        self.ai_logger = self._get_ai_logger()

    def log_usage(
        self,
        task_id: str,
        provider: str,
        model: str,
        usage_data: Dict[str, Any],
        cost: float,
    ):
        """è¨˜éŒ„ Token ä½¿ç”¨é‡åˆ°æ—¥èªŒ

        Args:
            task_id: ä»»å‹™ ID
            provider: AI æä¾›è€…
            model: æ¨¡å‹åç¨±
            usage_data: Token ä½¿ç”¨é‡è³‡æ–™
            cost: ä¼°ç®—æˆæœ¬
        """
        input_tokens = usage_data.get("input_tokens", 0)
        output_tokens = usage_data.get("output_tokens", 0)
        total_tokens = usage_data.get("total_tokens", 0)
        is_estimated = usage_data.get("estimated", False)

        # å»ºç«‹ Token ä½¿ç”¨è³‡è¨Š
        token_info = {
            "task_id": task_id,
            "provider": provider,
            "model": model,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "estimated_cost_usd": cost,
            "is_estimated": is_estimated,
        }

        # æ ¼å¼åŒ–æ—¥èªŒè¨Šæ¯
        formatted_usage = (
            f"Task: {task_id[:8]}... | "
            f"Provider: {provider.upper()} ({model}) | "
            f"Tokens: {input_tokens}â†’{output_tokens} (Total: {total_tokens})"
        )

        if is_estimated:
            formatted_usage += f" ğŸ“Šä¼°ç®—å€¼ | Cost: ~${cost:.6f} USD (ä¼°ç®—)"
            self.ai_logger.info(f"TOKEN_USAGE_ESTIMATED: {formatted_usage}")
        else:
            formatted_usage += f" | Cost: ${cost:.6f} USD"
            self.ai_logger.info(f"TOKEN_USAGE: {formatted_usage}")

        # è¨˜éŒ„åŸå§‹ JSON ä¾› API è§£æ
        self.ai_logger.debug(f"TOKEN_USAGE_RAW: {token_info}")

        # é¡¯ç¤ºæ§åˆ¶å°æ‘˜è¦
        self.display_summary(provider, total_tokens, cost, is_estimated)

    def display_summary(
        self, provider: str, total_tokens: int, cost: float, is_estimated: bool = False
    ):
        """åœ¨æ§åˆ¶å°é¡¯ç¤º Token ä½¿ç”¨é‡æ‘˜è¦

        Args:
            provider: AI æä¾›è€…
            total_tokens: ç¸½ Token æ•¸
            cost: ä¼°ç®—æˆæœ¬
            is_estimated: æ˜¯å¦ç‚ºä¼°ç®—å€¼
        """
        if is_estimated:
            if cost > 0.01:
                logger.warning(
                    f"ğŸ”¥ é«˜æˆæœ¬æŸ¥è©¢ - {provider.upper()}: ~{total_tokens} tokens (~${cost:.4f}) ğŸ“Šä¼°ç®—"
                )
            else:
                logger.info(
                    f"ğŸ“Š AI æŸ¥è©¢å®Œæˆ - {provider.upper()}: ~{total_tokens} tokens (~${cost:.4f}) ä¼°ç®—"
                )
        else:
            if cost > 0.01:
                logger.warning(
                    f"ğŸ”¥ é«˜æˆæœ¬æŸ¥è©¢ - {provider.upper()}: {total_tokens} tokens (${cost:.4f})"
                )
            else:
                logger.info(
                    f"ğŸ’¡ AI æŸ¥è©¢å®Œæˆ - {provider.upper()}: {total_tokens} tokens (${cost:.4f})"
                )

    def _get_ai_logger(self):
        """å»ºç«‹ AI æ¨¡çµ„å°ˆç”¨çš„æ—¥èªŒè¨˜éŒ„å™¨"""
        ai_logger = logging.getLogger("ai_service")
        ai_logger.setLevel(logging.DEBUG)

        if not ai_logger.handlers:
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.DEBUG)

            class TokenUsageFormatter(logging.Formatter):
                def format(self, record):
                    if "TOKEN_USAGE_ESTIMATED:" in record.getMessage():
                        return f"ğŸ“Š [TOKEN-ä¼°ç®—] {record.getMessage().replace('TOKEN_USAGE_ESTIMATED: ', '')}"
                    elif "TOKEN_USAGE:" in record.getMessage():
                        return f"ğŸ’° [TOKEN] {record.getMessage()}"
                    else:
                        return f"ğŸ¤– [AI] {record.levelname}: {record.getMessage()}"

            formatter = TokenUsageFormatter()
            console_handler.setFormatter(formatter)
            ai_logger.addHandler(console_handler)
            ai_logger.propagate = False

        return ai_logger
